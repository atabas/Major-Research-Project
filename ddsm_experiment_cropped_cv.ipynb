{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "U44OUNNb2opg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pydicom\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from IPython import display\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from matplotlib.pyplot import imread\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision.models import alexnet, vgg16, resnet152, resnet18, vgg19\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pyro\n",
    "from pyro.distributions import Normal, Categorical\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceMeanField_ELBO, TraceGraph_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro import poutine\n",
    "import pyro.optim as pyroopt\n",
    "import pyro.distributions as dist\n",
    "import pyro.contrib.bnn as bnn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.distributions.utils import lazy_property\n",
    "import math\n",
    "\n",
    "import torch.nn.functional as nnf\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim import SGD \n",
    "from torch.distributions import constraints\n",
    "import torchvision as torchv\n",
    "import torchvision.transforms as torchvt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "xdGfoa_CACyz",
    "outputId": "56d0c7dc-de32-47c4-9fe0-e8a8fee19e5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to mount your Google Drive.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "_8-0X2Cx2opo"
   },
   "outputs": [],
   "source": [
    "# Function for moving tensor or model to GPU\n",
    "def cuda(xs):\n",
    "    if torch.cuda.is_available():\n",
    "        if not isinstance(xs, (list, tuple)):\n",
    "            return xs.cuda()\n",
    "        else:\n",
    "            return [x.cuda() for x in xs]\n",
    "    else:\n",
    "        return xs\n",
    "\n",
    "# Custom class for defining dataset for training with augmentation\n",
    "class Dataset_Hdf5(Dataset):\n",
    "\n",
    "    def __init__(self, path, data_type, cv_index):\n",
    "        \"\"\" Intialize the dataset\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.file = h5py.File(path, 'r')\n",
    "        self.images = self.file['data'][self.file['cv_indices_{}_{}'.format(data_type, cv_index)]]\n",
    "        self.labels = self.file['labels'][self.file['cv_indices_{}_{}'.format(data_type, cv_index)]]\n",
    "                \n",
    "        self.len = self.images.shape[0]\n",
    "        if data_type == 'train':\n",
    "          self.transform = transforms.Compose([\n",
    "                                              transforms.ToPILImage(),\n",
    "                                              transforms.RandomRotation((0, 360)),\n",
    "                                              transforms.RandomHorizontalFlip(),\n",
    "                                              transforms.RandomVerticalFlip(),\n",
    "                                              transforms.ToTensor(),\n",
    "                                              transforms.Normalize([0.5], [0.5])])\n",
    "        else:\n",
    "          self.transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                              transforms.Normalize([0.5], [0.5])\n",
    "                                              ])\n",
    "\n",
    "    # You must override __getitem__ and __len__\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Get a sample from the dataset\n",
    "        \"\"\"\n",
    "        # unsqueeze adds dimension to image -> converts to 1x224x224 since we don't have rgb\n",
    "        return cuda(self.transform(self.images[index].astype('float32'))), \\\n",
    "                cuda(torch.tensor(self.labels[index], dtype=torch.long))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Total number of samples in the dataset\n",
    "        \"\"\"\n",
    "        return self.len\n",
    "\n",
    "# 64 * [224 * 224], 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "XG64nK722opq"
   },
   "outputs": [],
   "source": [
    "# Need to define loaders for train and test in PyTorch\n",
    "ddms_train_loader = torch.utils.data.DataLoader(Dataset_Hdf5('/content/drive/My Drive/ddsm_cropped_all.hdf5', 'train', 3), \n",
    "                                                batch_size=16, shuffle=True)\n",
    "ddms_test_loader = torch.utils.data.DataLoader(Dataset_Hdf5('/content/drive/My Drive/ddsm_cropped_all.hdf5', 'test', 3), \n",
    "                                               batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "B2xR7oLJeI1l",
    "outputId": "7b861ca5-6330-41a2-bd85-d84578431996"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
      "100%|██████████| 46827520/46827520 [00:00<00:00, 52126432.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=256, bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try transfer learning\n",
    "res_net = resnet18(pretrained=True)\n",
    "# First we freeze all layers\n",
    "for param in res_net.parameters():\n",
    "    param.requires_grad = False # frozen layer\n",
    "\n",
    "\n",
    "# Now we make later layers trainable\n",
    "for param in res_net.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in res_net.layer3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in res_net.avgpool.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = res_net.fc.in_features\n",
    "# Replace 1 FC with 3 new FC\n",
    "res_net.fc = nn.Sequential(\n",
    "                nn.Linear(in_features=num_ftrs, out_features=256, bias=False),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=256, out_features=128, bias=True),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=128, out_features=2, bias=True))\n",
    " \n",
    "# Move ResNet to GPU\n",
    "res_net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "V4Zv4oJ_2opz",
    "outputId": "c064500a-894f-4484-8ee5-65f49fa3b5f3"
   },
   "outputs": [],
   "source": [
    "# Adam optimizer\n",
    "# Mostly following learning rates from paper\n",
    "ddms_optimizer_res_net = torch.optim.Adam(\n",
    "    [                                         {\"params\": res_net.layer3.parameters(), \"lr\": 0.0001},\n",
    "                                              {\"params\": res_net.layer4.parameters(), \"lr\": 0.0001},\n",
    "                                              {\"params\": res_net.avgpool.parameters(), \"lr\": 0.0001},    \n",
    "                                              {\"params\": res_net.fc[0].parameters(), \"lr\": 0.0001},\n",
    "                                              {\"params\": res_net.fc[2].parameters(), \"lr\": 0.001},\n",
    "                                              {\"params\": res_net.fc[4].parameters(), \"lr\": 0.002},\n",
    "\n",
    "                                           ],  \n",
    "                                lr=0.0001, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "oq9Hh7pJ2op1"
   },
   "outputs": [],
   "source": [
    "# Training function for deterministic network\n",
    "def train(net, train_loader, criterion, optimizer, net_name, num_epochs=25):\n",
    "    net.train()\n",
    "    train_acc_max = 0\n",
    "    test_acc_max = 0\n",
    "\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.95)\n",
    "    \n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        net.train()\n",
    "\n",
    "        total = 0\n",
    "        correct = 0\n",
    "   \n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs.expand(-1, 3, -1, -1))\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        print('End of epoch {}, Loss {}'.format(epoch + 1, running_loss / len(train_loader)))\n",
    "        \n",
    "        train_acc = correct / total\n",
    "        test_acc = test(net, ddms_test_loader)\n",
    "        \n",
    "        # Saving best checkpoint based on performance on test data\n",
    "        if train_acc > train_acc_max:\n",
    "            train_acc_max = train_acc\n",
    "            save_checkpoint(epoch + 1, net, optimizer, train_acc, test_acc, net_name, 'train')\n",
    "            \n",
    "        if test_acc > test_acc_max:\n",
    "            test_acc_max = test_acc\n",
    "            save_checkpoint(epoch + 1, net, optimizer, train_acc, test_acc, net_name, 'test')\n",
    "\n",
    "    print('Finished Training')\n",
    "    \n",
    "def test(net, test_loader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader, 0):\n",
    "            images, labels = data\n",
    "            outputs = net(images.expand(-1, 3, -1, -1))\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "#             predicted = predicted.float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = correct / total\n",
    "    print('Accuracy of the network on the images: %d %%' % (100 * acc))\n",
    "    return acc\n",
    "    \n",
    "def save_checkpoint(epoch, net, optimizer, train_acc, test_acc, net_name, param):\n",
    "    checkpoint = {\n",
    "        'net': net.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'train_acc': train_acc,\n",
    "        'test_acc': test_acc\n",
    "    }\n",
    "    torch.save(checkpoint, '/content/drive/My Drive/{}_{}_best.chk'.format(net_name, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "MROU3wRKuGJq",
    "outputId": "ab18332b-101a-4123-bf3e-4fa8227fc6a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 1, Loss 0.657499263567083\n",
      "Accuracy of the network on the images: 76 %\n",
      "End of epoch 2, Loss 0.583149851770962\n",
      "Accuracy of the network on the images: 72 %\n",
      "End of epoch 3, Loss 0.5526510007241193\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 4, Loss 0.5356269629562602\n",
      "Accuracy of the network on the images: 78 %\n",
      "End of epoch 5, Loss 0.5392786863972159\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 6, Loss 0.5258482543861165\n",
      "Accuracy of the network on the images: 78 %\n",
      "End of epoch 7, Loss 0.5260945961755865\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 8, Loss 0.49786310511476856\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 9, Loss 0.5019566374666551\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 10, Loss 0.4954571559148676\n",
      "Accuracy of the network on the images: 81 %\n",
      "End of epoch 11, Loss 0.4826545992318322\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 12, Loss 0.4838136865812189\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 13, Loss 0.45991575454964356\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 14, Loss 0.450917348966879\n",
      "Accuracy of the network on the images: 80 %\n",
      "End of epoch 15, Loss 0.46002227418562947\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 16, Loss 0.4384559009005042\n",
      "Accuracy of the network on the images: 80 %\n",
      "End of epoch 17, Loss 0.44123005463796505\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 18, Loss 0.4451916542123346\n",
      "Accuracy of the network on the images: 80 %\n",
      "End of epoch 19, Loss 0.3995371194446788\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 20, Loss 0.4412258598734351\n",
      "Accuracy of the network on the images: 78 %\n",
      "End of epoch 21, Loss 0.4193064586204641\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 22, Loss 0.40068928651949937\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 23, Loss 0.3906009968589334\n",
      "Accuracy of the network on the images: 80 %\n",
      "End of epoch 24, Loss 0.3890972523128285\n",
      "Accuracy of the network on the images: 80 %\n",
      "End of epoch 25, Loss 0.38488261419184067\n",
      "Accuracy of the network on the images: 81 %\n",
      "End of epoch 26, Loss 0.39597513850997473\n",
      "Accuracy of the network on the images: 78 %\n",
      "End of epoch 27, Loss 0.3593380589695538\n",
      "Accuracy of the network on the images: 80 %\n",
      "End of epoch 28, Loss 0.3666524987886934\n",
      "Accuracy of the network on the images: 80 %\n",
      "End of epoch 29, Loss 0.365265366435051\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 30, Loss 0.33821993452661175\n",
      "Accuracy of the network on the images: 81 %\n",
      "End of epoch 31, Loss 0.35867842909167796\n",
      "Accuracy of the network on the images: 80 %\n",
      "End of epoch 32, Loss 0.3423709527534597\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 33, Loss 0.3331786439699285\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 34, Loss 0.3250312692102264\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 35, Loss 0.34497648714219825\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 36, Loss 0.31819779986844343\n",
      "Accuracy of the network on the images: 81 %\n",
      "End of epoch 37, Loss 0.32200545852675155\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 38, Loss 0.2858878534506349\n",
      "Accuracy of the network on the images: 78 %\n",
      "End of epoch 39, Loss 0.29038695473881326\n",
      "Accuracy of the network on the images: 78 %\n",
      "End of epoch 40, Loss 0.30552362194832633\n",
      "Accuracy of the network on the images: 80 %\n",
      "End of epoch 41, Loss 0.2885269191335229\n",
      "Accuracy of the network on the images: 81 %\n",
      "End of epoch 42, Loss 0.2937998418422306\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 43, Loss 0.2773606190786642\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 44, Loss 0.2833169358618119\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 45, Loss 0.27055490016937256\n",
      "Accuracy of the network on the images: 81 %\n",
      "End of epoch 46, Loss 0.24679004620103276\n",
      "Accuracy of the network on the images: 78 %\n",
      "End of epoch 47, Loss 0.2734960080069654\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 48, Loss 0.2586231446441482\n",
      "Accuracy of the network on the images: 80 %\n",
      "End of epoch 49, Loss 0.24440570298363182\n",
      "Accuracy of the network on the images: 78 %\n",
      "End of epoch 50, Loss 0.26986716319532955\n",
      "Accuracy of the network on the images: 78 %\n",
      "End of epoch 51, Loss 0.24641491897842463\n",
      "Accuracy of the network on the images: 78 %\n",
      "End of epoch 52, Loss 0.2657538660308894\n",
      "Accuracy of the network on the images: 80 %\n",
      "End of epoch 53, Loss 0.22504169743727234\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 54, Loss 0.22459146709126585\n",
      "Accuracy of the network on the images: 78 %\n",
      "End of epoch 55, Loss 0.24799312843995935\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 56, Loss 0.240784253968912\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 57, Loss 0.23901600666782435\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 58, Loss 0.21626622904749476\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 59, Loss 0.21076926247161978\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 60, Loss 0.24706539809703826\n",
      "Accuracy of the network on the images: 78 %\n",
      "End of epoch 61, Loss 0.23172892318928942\n",
      "Accuracy of the network on the images: 78 %\n",
      "End of epoch 62, Loss 0.2264515009434784\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 63, Loss 0.22511738236336148\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 64, Loss 0.2153723050128011\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 65, Loss 0.2228905753177755\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 66, Loss 0.21324911954648354\n",
      "Accuracy of the network on the images: 78 %\n",
      "End of epoch 67, Loss 0.21503167446045315\n",
      "Accuracy of the network on the images: 78 %\n",
      "End of epoch 68, Loss 0.2270632959464017\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 69, Loss 0.21070379798903185\n",
      "Accuracy of the network on the images: 78 %\n",
      "End of epoch 70, Loss 0.21335878402871244\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 71, Loss 0.20067196803934434\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 72, Loss 0.23198840469121934\n",
      "Accuracy of the network on the images: 78 %\n",
      "End of epoch 73, Loss 0.2051573139779708\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 74, Loss 0.22416185232646324\n",
      "Accuracy of the network on the images: 78 %\n",
      "End of epoch 75, Loss 0.2394132100045681\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 76, Loss 0.22122150826103548\n",
      "Accuracy of the network on the images: 78 %\n",
      "End of epoch 77, Loss 0.23908977403360254\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 78, Loss 0.2148941325790742\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 79, Loss 0.21014076138243956\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 80, Loss 0.2209092961076428\n",
      "Accuracy of the network on the images: 78 %\n",
      "End of epoch 81, Loss 0.22009769003180896\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 82, Loss 0.21657759126494913\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 83, Loss 0.20967137059744667\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 84, Loss 0.2240636507377905\n",
      "Accuracy of the network on the images: 78 %\n",
      "End of epoch 85, Loss 0.2154548733988229\n",
      "Accuracy of the network on the images: 78 %\n",
      "End of epoch 86, Loss 0.2006498721154297\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 87, Loss 0.21259473978596574\n",
      "Accuracy of the network on the images: 76 %\n",
      "End of epoch 88, Loss 0.21688816928688218\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 89, Loss 0.19577074195532237\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 90, Loss 0.222107370197773\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 91, Loss 0.18459128264118643\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 92, Loss 0.21209294252535876\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 93, Loss 0.20654661458204773\n",
      "Accuracy of the network on the images: 78 %\n",
      "End of epoch 94, Loss 0.21613165674840704\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 95, Loss 0.19948820660219474\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 96, Loss 0.18986443434568012\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 97, Loss 0.21311696693301202\n",
      "Accuracy of the network on the images: 76 %\n",
      "End of epoch 98, Loss 0.2096747964839725\n",
      "Accuracy of the network on the images: 79 %\n",
      "End of epoch 99, Loss 0.20154263697126332\n",
      "Accuracy of the network on the images: 77 %\n",
      "End of epoch 100, Loss 0.1997117708711063\n",
      "Accuracy of the network on the images: 78 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(res_net, ddms_train_loader, ddms_criterion, ddms_optimizer_res_net, 'res_net_custom_cropped_exp_2', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "SKkJ2fWeQ6Ip",
    "outputId": "5cc82104-7ee9-4bb9-bb30-8e722d8c760d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 78.8MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=256, bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demonstration that saved checkpoint can be loaded \n",
    "ckpt = torch.load('/content/drive/My Drive/res_net_custom_cropped_exp_2_test_best.chk')\n",
    "res_net_saved = resnet18(pretrained=True)\n",
    "for param in res_net_saved.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = res_net_saved.fc.in_features\n",
    "res_net_saved.fc = nn.Sequential(\n",
    "                nn.Linear(in_features=num_ftrs, out_features=256, bias=False),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=256, out_features=128, bias=True),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=128, out_features=2, bias=True))\n",
    "res_net_saved.load_state_dict(ckpt['net'])\n",
    "res_net_saved.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "HAMgFefASNmb"
   },
   "outputs": [],
   "source": [
    "# Separate feature generator (everything except FC block)\n",
    "fgen = nn.Sequential(*list(res_net_saved.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "vWN5rjzaV-nB",
    "outputId": "8ebad7b9-650c-4530-9eec-1aca4c9ec4e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 224, 224])"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(ddms_test_loader).next()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "vj6BGoJWaHOn",
    "outputId": "30f85c9b-43f5-4cb6-c971-1ee972530a45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357\n",
      "339\n"
     ]
    }
   ],
   "source": [
    "# See how many images are in training set and test set\n",
    "total = 0\n",
    "test_total = 0\n",
    "for x, _ in ddms_train_loader:\n",
    "    total += x.shape[0]\n",
    "print(total)\n",
    "for x, _ in ddms_test_loader:\n",
    "    test_total += x.shape[0]\n",
    "print(test_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "dBgsudVUVq4t"
   },
   "outputs": [],
   "source": [
    "# we will generate 10 times more training data than the original training data size using data augmentation\n",
    "train_features = np.zeros((total * 10, num_ftrs)).astype('float32')\n",
    "train_labels = np.zeros(total * 10).astype('int64')\n",
    "test_features = np.zeros((test_total, num_ftrs)).astype('float32')\n",
    "test_labels = np.zeros(test_total).astype('int64')\n",
    "index  = 0\n",
    "for e in range(10):\n",
    "    for data, labels in ddms_train_loader:\n",
    "        # each generated train feature will be a 512 element vector\n",
    "        train_features[index:index + data.shape[0]] = fgen(data.expand(-1, 3, -1, -1)).view(data.shape[0], num_ftrs).cpu()\n",
    "        # labels is in GPU, so transfer it to CPU first to assign to the numpy array\n",
    "        train_labels[index:index + data.shape[0]] = labels.cpu()\n",
    "        index += data.shape[0]\n",
    "\n",
    "index = 0\n",
    "for data, labels in ddms_test_loader:\n",
    "    test_features[index:index + data.shape[0]] = fgen(data.expand(-1, 3, -1, -1)).view(data.shape[0], num_ftrs).cpu()\n",
    "    test_labels[index:index + data.shape[0]] = labels.cpu()\n",
    "    index += data.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "sZyyKUGGtBL8"
   },
   "outputs": [],
   "source": [
    "# Network for Bayesian purpose, 3 fully connected layers\n",
    "class BayesNet(nn.Module):\n",
    "    def __init__(self, num_ftrs):\n",
    "        super(BayesNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=num_ftrs, out_features=256, bias=True)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=128, bias=True)\n",
    "        self.fc3 = nn.Linear(in_features=128, out_features=2, bias=True)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "uq-qW2o3xMuA",
    "outputId": "d870982b-07d3-42d6-9558-3f5e9afc302a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesNet(\n",
       "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnet = BayesNet(num_ftrs)\n",
    "bnet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zQxfjTQ1x3QU"
   },
   "outputs": [],
   "source": [
    "class DataSetBayes(Dataset):\n",
    "\n",
    "    def __init__(self, data, labels):\n",
    "        \"\"\" Intialize the dataset\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "                \n",
    "        self.len = self.data.shape[0]\n",
    "\n",
    "    # You must override __getitem__ and __len__\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Get a sample from the dataset\n",
    "        \"\"\"\n",
    "        return self.data[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Total number of samples in the dataset\n",
    "        \"\"\"\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "gt0ZQqPp2oqD"
   },
   "outputs": [],
   "source": [
    "bayes_train_loader = torch.utils.data.DataLoader(DataSetBayes(train_features, train_labels), \n",
    "                                                batch_size=8, shuffle=True)\n",
    "bayes_test_loader = torch.utils.data.DataLoader(DataSetBayes(test_features, test_labels), \n",
    "                                               batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "TatGWBIal7PU"
   },
   "outputs": [],
   "source": [
    "# functions for Bayesian training needed in Pyro, model() and guide() \n",
    "log_softmax = nn.LogSoftmax(dim=1)\n",
    "def model_bayes_net(x_data, y_data):\n",
    "    fc1w_prior = Normal(loc=torch.zeros_like(bnet.fc1.weight).cuda(), scale=torch.ones_like(bnet.fc1.weight).cuda())\n",
    "    fc1b_prior = Normal(loc=torch.zeros_like(bnet.fc1.bias).cuda(), scale=torch.ones_like(bnet.fc1.bias).cuda())\n",
    "    \n",
    "    fc2w_prior = Normal(loc=torch.zeros_like(bnet.fc2.weight).cuda(), scale=torch.ones_like(bnet.fc2.weight).cuda())\n",
    "    fc2b_prior = Normal(loc=torch.zeros_like(bnet.fc2.bias).cuda(), scale=torch.ones_like(bnet.fc2.bias).cuda())\n",
    "    \n",
    "    fc3w_prior = Normal(loc=torch.zeros_like(bnet.fc3.weight).cuda(), scale=torch.ones_like(bnet.fc3.weight).cuda())\n",
    "    fc3b_prior = Normal(loc=torch.zeros_like(bnet.fc3.bias).cuda(), scale=torch.ones_like(bnet.fc3.bias).cuda())\n",
    "\n",
    "    \n",
    "    priors = {'fc1.weight': fc1w_prior, \n",
    "              'fc1.bias': fc1b_prior, \n",
    "              'fc2.weight': fc2w_prior, \n",
    "              'fc2.bias': fc2b_prior, \n",
    "              'fc3.weight': fc3w_prior, \n",
    "              'fc3.bias': fc3b_prior}\n",
    "    # lift module parameters to random variables sampled from the priors\n",
    "    lifted_module = pyro.random_module(\"module\", bnet, priors)\n",
    "    # sample a regressor (which also samples w and b)\n",
    "    lifted_reg_model = lifted_module()\n",
    "\n",
    "    lhat = log_softmax(lifted_reg_model(x_data))\n",
    "    \n",
    "    pyro.sample(\"obs\", Categorical(logits=lhat), obs=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jxVnkasnpYRU"
   },
   "outputs": [],
   "source": [
    "softplus = torch.nn.Softplus()\n",
    "\n",
    "def guide_bayes_net(x_data, y_data):\n",
    "    # First fully connected layer weight distribution priors\n",
    "    fc1w_mu = torch.randn_like(bnet.fc1.weight).cuda()\n",
    "    fc1w_sigma = torch.randn_like(bnet.fc1.weight).cuda()\n",
    "    fc1w_mu_param = pyro.param(\"fc1w_mu\", fc1w_mu)\n",
    "    fc1w_sigma_param = softplus(pyro.param(\"fc1w_sigma\", fc1w_sigma))\n",
    "    fc1w_prior = Normal(loc=fc1w_mu_param, scale=fc1w_sigma_param)\n",
    "    # First fully connected layer bias distribution priors\n",
    "    fc1b_mu = torch.randn_like(bnet.fc1.bias).cuda()\n",
    "    fc1b_sigma = torch.randn_like(bnet.fc1.bias).cuda()\n",
    "    fc1b_mu_param = pyro.param(\"fc1b_mu\", fc1b_mu)\n",
    "    fc1b_sigma_param = softplus(pyro.param(\"fc1b_sigma\", fc1b_sigma))\n",
    "    fc1b_prior = Normal(loc=fc1b_mu_param, scale=fc1b_sigma_param)\n",
    "    # Second fully connected layer weight distribution priors\n",
    "    fc2w_mu = torch.randn_like(bnet.fc2.weight).cuda()\n",
    "    fc2w_sigma = torch.randn_like(bnet.fc2.weight).cuda()\n",
    "    fc2w_mu_param = pyro.param(\"fc2w_mu\", fc2w_mu)\n",
    "    fc2w_sigma_param = softplus(pyro.param(\"fc2w_sigma\", fc2w_sigma))\n",
    "    fc2w_prior = Normal(loc=fc2w_mu_param, scale=fc2w_sigma_param)\n",
    "    # Second fully connected layer bias distribution priors\n",
    "    fc2b_mu = torch.randn_like(bnet.fc2.bias).cuda()\n",
    "    fc2b_sigma = torch.randn_like(bnet.fc2.bias).cuda()\n",
    "    fc2b_mu_param = pyro.param(\"fc2b_mu\", fc2b_mu)\n",
    "    fc2b_sigma_param = softplus(pyro.param(\"fc2b_sigma\", fc2b_sigma))\n",
    "    fc2b_prior = Normal(loc=fc2b_mu_param, scale=fc2b_sigma_param)\n",
    "    # Third fully connected layer weight distribution priors\n",
    "    fc3w_mu = torch.randn_like(bnet.fc3.weight).cuda()\n",
    "    fc3w_sigma = torch.randn_like(bnet.fc3.weight).cuda()\n",
    "    fc3w_mu_param = pyro.param(\"fc3w_mu\", fc3w_mu)\n",
    "    fc3w_sigma_param = softplus(pyro.param(\"fc3w_sigma\", fc3w_sigma))\n",
    "    fc3w_prior = Normal(loc=fc3w_mu_param, scale=fc3w_sigma_param)\n",
    "    # Third fully connected layer bias distribution priors\n",
    "    fc3b_mu = torch.randn_like(bnet.fc3.bias).cuda()\n",
    "    fc3b_sigma = torch.randn_like(bnet.fc3.bias).cuda()\n",
    "    fc3b_mu_param = pyro.param(\"fc3b_mu\", fc3b_mu)\n",
    "    fc3b_sigma_param = softplus(pyro.param(\"fc3b_sigma\", fc3b_sigma))\n",
    "    fc3b_prior = Normal(loc=fc3b_mu_param, scale=fc3b_sigma_param)\n",
    "    \n",
    "    priors = {'fc1.weight': fc1w_prior, \n",
    "              'fc1.bias': fc1b_prior, \n",
    "              'fc2.weight': fc2w_prior, \n",
    "              'fc2.bias': fc2b_prior, \n",
    "              'fc3.weight': fc3w_prior, \n",
    "              'fc3.bias': fc3b_prior}\n",
    "    \n",
    "    lifted_module = pyro.random_module(\"module\", bnet, priors)\n",
    "    \n",
    "    return lifted_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "_Bc1Wqxy2oqP"
   },
   "outputs": [],
   "source": [
    "# function for different learning rates at different layers\n",
    "def get_optim_args(module_name, param_name):\n",
    "    if param_name == 'fc1.weight' or param_name == 'fc1.bias':\n",
    "        return {\"lr\": 0.0001, 'betas': (0.5, 0.999)}\n",
    "    elif param_name == 'fc2.weight' or param_name == 'fc2.bias':\n",
    "        return {\"lr\": 0.001, 'betas': (0.5, 0.999)}\n",
    "    else:\n",
    "        return {\"lr\": 0.002, 'betas': (0.5, 0.999)}\n",
    "    \n",
    "optim = torch.optim.Adam\n",
    "scheduler = pyro.optim.StepLR({'optimizer': optim,  'optim_args': get_optim_args,\n",
    "                               'step_size': 5, 'gamma': 0.1})\n",
    "\n",
    "# define stochastic variational inference\n",
    "svi = SVI(model_bayes_net, guide_bayes_net, scheduler, loss=Trace_ELBO())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "KyxqGMMp2oqR",
    "outputId": "0774b32e-2185-47c2-9874-d062a009e3d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  Loss  15638.837418734029\n",
      "Epoch  1  Loss  8528.736376881132\n",
      "Epoch  2  Loss  3899.6411283448256\n",
      "Epoch  3  Loss  1551.1354187588793\n",
      "Epoch  4  Loss  622.9060791623598\n",
      "Epoch  5  Loss  313.27244874770446\n",
      "Epoch  6  Loss  240.09437875786196\n",
      "Epoch  7  Loss  221.8147793499586\n",
      "Epoch  8  Loss  209.39330723049747\n",
      "Epoch  9  Loss  199.755452349664\n"
     ]
    }
   ],
   "source": [
    "# bayesian training\n",
    "\n",
    "num_iterations = 10\n",
    "loss = 0\n",
    "\n",
    "for j in range(num_iterations):\n",
    "    loss = 0\n",
    "    for batch_id, data in enumerate(bayes_train_loader):\n",
    "        # calculate the loss and take a gradient step for updating the weight distributions\n",
    "        loss += svi.step(data[0].cuda(), data[1].cuda())\n",
    "    normalizer_train = len(bayes_train_loader.dataset)\n",
    "    total_epoch_loss_train = loss / normalizer_train\n",
    "    scheduler.step(epoch=j)\n",
    "    \n",
    "    print(\"Epoch \", j, \" Loss \", total_epoch_loss_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "HrGGoGVb2oqS",
    "outputId": "39d6152c-274d-4f2f-8407-1e942b99a6d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction when network is forced to predict\n",
      "accuracy: 81 %\n"
     ]
    }
   ],
   "source": [
    "# evaluation with the sampled networks\n",
    "\n",
    "num_samples = 1000\n",
    "def predict(x):\n",
    "    sampled_models = [guide_bayes_net(None, None) for _ in range(num_samples)]\n",
    "    yhats = [model(x).data for model in sampled_models]\n",
    "    mean = torch.mean(torch.stack(yhats), 0)\n",
    "    return np.argmax(mean.cpu().numpy(), axis=1)\n",
    "\n",
    "# forced prediction based on sum of probability for each label across all 1000 networks\n",
    "print('Prediction when network is forced to predict')\n",
    "correct = 0\n",
    "total = 0\n",
    "for j, data in enumerate(bayes_test_loader):\n",
    "    dat, labels = data\n",
    "    predicted = predict(dat.cuda())\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels.numpy()).sum().item()\n",
    "print(\"accuracy: %d %%\" % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "L9P6FiZ62oqU"
   },
   "outputs": [],
   "source": [
    "classes = ('BENIGN', 'MALIGNANT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jjo2t15L2oqV"
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(1, 1))\n",
    "    ax.imshow(npimg,  cmap='gray', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zMcShRFpIeMn"
   },
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "sampled_models = [guide_bayes_net(None, None) for _ in range(num_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "BdPOwUA_2oqW"
   },
   "outputs": [],
   "source": [
    "# helper method for getting prediction probabilities for each sampled network\n",
    "def give_uncertainities(x):\n",
    "    yhats = [F.log_softmax(model(x).data, 1).detach().cpu().numpy() for model in sampled_models]\n",
    "    return np.asarray(yhats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "7ZuUszwe2oqZ"
   },
   "outputs": [],
   "source": [
    "# method for tuning N and P and calculating accuracy\n",
    "# N = threshold\n",
    "# P = min_prob\n",
    "def test_batch(images, labels, threshold=0.8, min_prob=0.7, plot=True):\n",
    "    y = give_uncertainities(images)\n",
    "    predicted_for_images = 0\n",
    "    correct_predictions=0\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "    \n",
    "        if(plot):\n",
    "            print(\"Real: \",labels[i].item())\n",
    "            fig, axs = plt.subplots(1, 3, sharey=True,figsize=(20,2))\n",
    "    \n",
    "        all_labels_prob = []\n",
    "    \n",
    "        highted_something = False\n",
    "    \n",
    "        for j in range(len(classes)):\n",
    "        \n",
    "            highlight=False\n",
    "        \n",
    "            histo = []\n",
    "            histo_exp = []\n",
    "        \n",
    "            for z in range(y.shape[0]):\n",
    "                histo.append(y[z][i][j])\n",
    "                histo_exp.append(np.exp(y[z][i][j]))\n",
    "            \n",
    "            histo_exp = np.array(histo_exp)\n",
    "            count = np.where(histo_exp > min_prob)[0].shape[0]\n",
    "  \n",
    "            if count > num_samples * threshold:\n",
    "              highlight = True\n",
    "        \n",
    "            all_labels_prob.append(count)\n",
    "            \n",
    "            if(plot):\n",
    "            \n",
    "                N, bins, patches = axs[j].hist(histo, bins=8, color = \"lightgray\", lw=0,  weights=np.ones(len(histo)) / len(histo), density=False)\n",
    "                axs[j].set_title(str(j)+\" (\"+str(round(prob,2))+\")\") \n",
    "        \n",
    "            if(highlight):\n",
    "            \n",
    "                highted_something = True\n",
    "                \n",
    "                if(plot):\n",
    "\n",
    "                    # We'll color code by height, but you could use any scalar\n",
    "                    fracs = N / N.max()\n",
    "\n",
    "                    # we need to normalize the data to 0..1 for the full range of the colormap\n",
    "                    norm = colors.Normalize(fracs.min(), fracs.max())\n",
    "\n",
    "                    # Now, we'll loop through our objects and set the color of each accordingly\n",
    "                    for thisfrac, thispatch in zip(fracs, patches):\n",
    "                        color = plt.cm.viridis(norm(thisfrac))\n",
    "                        thispatch.set_facecolor(color)\n",
    "\n",
    "    \n",
    "        if(plot):\n",
    "            plt.show()\n",
    "    \n",
    "        predicted = np.argmax(all_labels_prob)\n",
    "    \n",
    "        if(highted_something):\n",
    "            predicted_for_images+=1\n",
    "            if(labels[i].item()==predicted):\n",
    "                if(plot):\n",
    "                    print(\"Correct\")\n",
    "                correct_predictions +=1.0\n",
    "            else:\n",
    "                if(plot):\n",
    "                    print(\"Incorrect :()\")\n",
    "        else:\n",
    "            if(plot):\n",
    "                print(\"Undecided.\")\n",
    "        \n",
    "        if(plot):\n",
    "            imshow(images[i].squeeze())\n",
    "        \n",
    "    \n",
    "    if(plot):\n",
    "        print(\"Summary\")\n",
    "        print(\"Total images: \",len(labels))\n",
    "        print(\"Predicted for: \",predicted_for_images)\n",
    "        print(\"Accuracy when predicted: \",correct_predictions/predicted_for_images)\n",
    "        \n",
    "    return len(labels), correct_predictions, predicted_for_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "MUBTDSKs2oqa",
    "outputId": "7836ab2f-4a56-47b2-b27d-825de49dc030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction when network can refuse\n",
      "Total images:  339\n",
      "Skipped:  337\n",
      "Accuracy when made predictions: 100 %\n"
     ]
    }
   ],
   "source": [
    "# Prediction when network can decide not to predict\n",
    "print('Prediction when network can refuse')\n",
    "correct = 0\n",
    "total = 0\n",
    "total_predicted_for = 0\n",
    "for j, data in enumerate(bayes_test_loader):\n",
    "    images, labels = data\n",
    "    \n",
    "    total_minibatch, correct_minibatch, predictions_minibatch = test_batch(images.cuda(), labels.cuda(), 0.75, 0.7, plot=False)\n",
    "    total += total_minibatch\n",
    "    correct += correct_minibatch\n",
    "    total_predicted_for += predictions_minibatch\n",
    "\n",
    "print(\"Total images: \", total)\n",
    "print(\"Skipped: \", total-total_predicted_for)\n",
    "print(\"Accuracy when made predictions: %d %%\" % (100 * correct / total_predicted_for))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "lnLKfFegM2Rm",
    "outputId": "b00be1a8-c5de-45da-e112-902f8e641ddc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N and P tuning result generation\n"
     ]
    }
   ],
   "source": [
    "print('N and P tuning result generation')\n",
    "results = []\n",
    "ns = [0.95, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2]\n",
    "ps = [0.95, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2]\n",
    "\n",
    "for N in ns:\n",
    "    for P in ps:\n",
    "        result = []\n",
    "        result.append(N)\n",
    "        result.append(P)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        total_predicted_for = 0\n",
    "        for j, data in enumerate(bayes_test_loader):\n",
    "            images, labels = data\n",
    "\n",
    "            total_minibatch, correct_minibatch, predictions_minibatch = test_batch(images.cuda(), labels.cuda(), N, P, plot=False)\n",
    "            total += total_minibatch\n",
    "            correct += correct_minibatch\n",
    "            total_predicted_for += predictions_minibatch\n",
    "        result.append(total)\n",
    "        result.append(total-total_predicted_for)\n",
    "        if total_predicted_for > 0:\n",
    "            result.append(correct / total_predicted_for)\n",
    "        else:\n",
    "            result.append(-1)\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "mc8VSjXpVlQ0",
    "outputId": "45165359-6507-4d0f-fc64-7cbc1fb286c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>Total Images</th>\n",
       "      <th>Skipped Images</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>339</td>\n",
       "      <td>339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.90</td>\n",
       "      <td>339</td>\n",
       "      <td>339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.85</td>\n",
       "      <td>339</td>\n",
       "      <td>339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.80</td>\n",
       "      <td>339</td>\n",
       "      <td>339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.75</td>\n",
       "      <td>339</td>\n",
       "      <td>339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.70</td>\n",
       "      <td>339</td>\n",
       "      <td>339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.65</td>\n",
       "      <td>339</td>\n",
       "      <td>339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.60</td>\n",
       "      <td>339</td>\n",
       "      <td>339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.55</td>\n",
       "      <td>339</td>\n",
       "      <td>339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.50</td>\n",
       "      <td>339</td>\n",
       "      <td>339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.45</td>\n",
       "      <td>339</td>\n",
       "      <td>339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.40</td>\n",
       "      <td>339</td>\n",
       "      <td>339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.35</td>\n",
       "      <td>339</td>\n",
       "      <td>339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.30</td>\n",
       "      <td>339</td>\n",
       "      <td>339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.25</td>\n",
       "      <td>339</td>\n",
       "      <td>339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.20</td>\n",
       "      <td>339</td>\n",
       "      <td>339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.95</td>\n",
       "      <td>339</td>\n",
       "      <td>337</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>339</td>\n",
       "      <td>337</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.85</td>\n",
       "      <td>339</td>\n",
       "      <td>337</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.80</td>\n",
       "      <td>339</td>\n",
       "      <td>337</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.75</td>\n",
       "      <td>339</td>\n",
       "      <td>337</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.70</td>\n",
       "      <td>339</td>\n",
       "      <td>337</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.65</td>\n",
       "      <td>339</td>\n",
       "      <td>337</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.60</td>\n",
       "      <td>339</td>\n",
       "      <td>337</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.55</td>\n",
       "      <td>339</td>\n",
       "      <td>337</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.50</td>\n",
       "      <td>339</td>\n",
       "      <td>337</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.45</td>\n",
       "      <td>339</td>\n",
       "      <td>336</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.008850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.40</td>\n",
       "      <td>339</td>\n",
       "      <td>336</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.008850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.35</td>\n",
       "      <td>339</td>\n",
       "      <td>336</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.008850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.30</td>\n",
       "      <td>339</td>\n",
       "      <td>336</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.008850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.85</td>\n",
       "      <td>339</td>\n",
       "      <td>293</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.135693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>339</td>\n",
       "      <td>293</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.135693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>339</td>\n",
       "      <td>291</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.141593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.70</td>\n",
       "      <td>339</td>\n",
       "      <td>290</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.144543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.65</td>\n",
       "      <td>339</td>\n",
       "      <td>288</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.150442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>339</td>\n",
       "      <td>288</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.150442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.55</td>\n",
       "      <td>339</td>\n",
       "      <td>286</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.156342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.50</td>\n",
       "      <td>339</td>\n",
       "      <td>285</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.159292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.45</td>\n",
       "      <td>339</td>\n",
       "      <td>284</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.162242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.40</td>\n",
       "      <td>339</td>\n",
       "      <td>284</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.162242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.35</td>\n",
       "      <td>339</td>\n",
       "      <td>284</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.162242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.30</td>\n",
       "      <td>339</td>\n",
       "      <td>282</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.168142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.25</td>\n",
       "      <td>339</td>\n",
       "      <td>281</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.171091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>339</td>\n",
       "      <td>279</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.176991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.95</td>\n",
       "      <td>339</td>\n",
       "      <td>273</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.194690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.90</td>\n",
       "      <td>339</td>\n",
       "      <td>272</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.197640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.85</td>\n",
       "      <td>339</td>\n",
       "      <td>272</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.197640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>339</td>\n",
       "      <td>271</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.200590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>339</td>\n",
       "      <td>270</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.203540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.70</td>\n",
       "      <td>339</td>\n",
       "      <td>270</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.203540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.65</td>\n",
       "      <td>339</td>\n",
       "      <td>266</td>\n",
       "      <td>0.945205</td>\n",
       "      <td>0.215339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.60</td>\n",
       "      <td>339</td>\n",
       "      <td>266</td>\n",
       "      <td>0.945205</td>\n",
       "      <td>0.215339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.55</td>\n",
       "      <td>339</td>\n",
       "      <td>261</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.230088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>339</td>\n",
       "      <td>257</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.241888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.45</td>\n",
       "      <td>339</td>\n",
       "      <td>249</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.265487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.40</td>\n",
       "      <td>339</td>\n",
       "      <td>239</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.294985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.35</td>\n",
       "      <td>339</td>\n",
       "      <td>221</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.348083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.30</td>\n",
       "      <td>339</td>\n",
       "      <td>214</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.368732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>339</td>\n",
       "      <td>205</td>\n",
       "      <td>0.932836</td>\n",
       "      <td>0.395280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.20</td>\n",
       "      <td>339</td>\n",
       "      <td>195</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.424779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       N     P  Total Images  Skipped Images  Accuracy  Coverage\n",
       "0   0.95  0.95           339             339       NaN  0.000000\n",
       "1   0.95  0.90           339             339       NaN  0.000000\n",
       "2   0.95  0.85           339             339       NaN  0.000000\n",
       "3   0.95  0.80           339             339       NaN  0.000000\n",
       "4   0.95  0.75           339             339       NaN  0.000000\n",
       "5   0.95  0.70           339             339       NaN  0.000000\n",
       "6   0.95  0.65           339             339       NaN  0.000000\n",
       "7   0.95  0.60           339             339       NaN  0.000000\n",
       "8   0.95  0.55           339             339       NaN  0.000000\n",
       "9   0.95  0.50           339             339       NaN  0.000000\n",
       "10  0.95  0.45           339             339       NaN  0.000000\n",
       "11  0.95  0.40           339             339       NaN  0.000000\n",
       "12  0.95  0.35           339             339       NaN  0.000000\n",
       "13  0.95  0.30           339             339       NaN  0.000000\n",
       "14  0.95  0.25           339             339       NaN  0.000000\n",
       "15  0.95  0.20           339             339       NaN  0.000000\n",
       "16  0.90  0.95           339             337  0.500000  0.005900\n",
       "17  0.90  0.90           339             337  0.500000  0.005900\n",
       "18  0.90  0.85           339             337  0.500000  0.005900\n",
       "19  0.90  0.80           339             337  0.500000  0.005900\n",
       "20  0.90  0.75           339             337  0.500000  0.005900\n",
       "21  0.90  0.70           339             337  0.500000  0.005900\n",
       "22  0.90  0.65           339             337  0.500000  0.005900\n",
       "23  0.90  0.60           339             337  0.500000  0.005900\n",
       "24  0.90  0.55           339             337  0.500000  0.005900\n",
       "25  0.90  0.50           339             337  0.500000  0.005900\n",
       "26  0.90  0.45           339             336  0.666667  0.008850\n",
       "27  0.90  0.40           339             336  0.666667  0.008850\n",
       "28  0.90  0.35           339             336  0.666667  0.008850\n",
       "29  0.90  0.30           339             336  0.666667  0.008850\n",
       "..   ...   ...           ...             ...       ...       ...\n",
       "50  0.80  0.85           339             293  0.978261  0.135693\n",
       "51  0.80  0.80           339             293  0.978261  0.135693\n",
       "52  0.80  0.75           339             291  0.979167  0.141593\n",
       "53  0.80  0.70           339             290  0.979592  0.144543\n",
       "54  0.80  0.65           339             288  0.980392  0.150442\n",
       "55  0.80  0.60           339             288  0.980392  0.150442\n",
       "56  0.80  0.55           339             286  0.962264  0.156342\n",
       "57  0.80  0.50           339             285  0.944444  0.159292\n",
       "58  0.80  0.45           339             284  0.945455  0.162242\n",
       "59  0.80  0.40           339             284  0.945455  0.162242\n",
       "60  0.80  0.35           339             284  0.945455  0.162242\n",
       "61  0.80  0.30           339             282  0.947368  0.168142\n",
       "62  0.80  0.25           339             281  0.948276  0.171091\n",
       "63  0.80  0.20           339             279  0.950000  0.176991\n",
       "64  0.75  0.95           339             273  0.939394  0.194690\n",
       "65  0.75  0.90           339             272  0.940299  0.197640\n",
       "66  0.75  0.85           339             272  0.940299  0.197640\n",
       "67  0.75  0.80           339             271  0.941176  0.200590\n",
       "68  0.75  0.75           339             270  0.942029  0.203540\n",
       "69  0.75  0.70           339             270  0.942029  0.203540\n",
       "70  0.75  0.65           339             266  0.945205  0.215339\n",
       "71  0.75  0.60           339             266  0.945205  0.215339\n",
       "72  0.75  0.55           339             261  0.948718  0.230088\n",
       "73  0.75  0.50           339             257  0.939024  0.241888\n",
       "74  0.75  0.45           339             249  0.944444  0.265487\n",
       "75  0.75  0.40           339             239  0.920000  0.294985\n",
       "76  0.75  0.35           339             221  0.932203  0.348083\n",
       "77  0.75  0.30           339             214  0.936000  0.368732\n",
       "78  0.75  0.25           339             205  0.932836  0.395280\n",
       "79  0.75  0.20           339             195  0.930556  0.424779\n",
       "\n",
       "[80 rows x 6 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results, columns=[\"N\", \"P\", \"Total Images\", \"Skipped Images\", \"Accuracy\"])\n",
    "results_df['Accuracy']\n",
    "results_df.loc[results_df['Accuracy'] == -1, 'Accuracy'] = np.NaN\n",
    "results_df['Coverage'] = (results_df['Total Images'] - results_df['Skipped Images']) / results_df['Total Images']\n",
    "results_df.to_csv('/content/drive/My Drive/tuning_results_3.csv')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "DZrGzDpUa61S",
    "outputId": "791010c4-2389-4659-8f90-394c366119ef"
   },
   "outputs": [],
   "source": [
    "results_df[results_df['N'] == 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ocp4ZcKlbrqe"
   },
   "outputs": [],
   "source": [
    "results_df.to_csv('/content/drive/My Drive/tuning_results_3_ext.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "WvKolkCbQfp9"
   },
   "outputs": [],
   "source": [
    "# save the training labels to a pickle file for later use\n",
    "with open ('/content/drive/My Drive/train_labels.pkl', 'wb') as f:\n",
    "    pickle.dump(train_labels, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "vey4qB3JRpgs"
   },
   "outputs": [],
   "source": [
    "# save the 1000 sampled models to a checkpoint file for later use\n",
    "checkpoints = {}\n",
    "for i, model in enumerate(sampled_models):\n",
    "    checkpoints['model{}'.format(i)] = model.state_dict()\n",
    "torch.save(checkpoints, '/content/drive/My Drive/bayesian_models.chk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hbNIR7oLTW7N"
   },
   "outputs": [],
   "source": [
    "# load the above saved checkpoint\n",
    "ckptb = torch.load('/content/drive/My Drive/bayesian_models.chk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "68ZziuQVTcOZ",
    "outputId": "bfb3944c-0f7e-4e1b-97b2-e1641927c9b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4479e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -4.7416e+02],\n",
       "        [-7.9243e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -9.1107e+02],\n",
       "        [-8.2344e+02,  0.0000e+00],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [ 0.0000e+00, -1.3178e+02],\n",
       "        [-1.4924e+00, -2.5468e-01],\n",
       "        [ 0.0000e+00, -2.1102e+02],\n",
       "        [-4.6472e+01,  0.0000e+00],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [-1.0362e+03,  0.0000e+00],\n",
       "        [ 0.0000e+00, -1.7131e+02],\n",
       "        [-1.1197e+02,  0.0000e+00],\n",
       "        [-2.0199e+02,  0.0000e+00],\n",
       "        [-4.9591e-05, -9.9187e+00],\n",
       "        [-5.4628e-01, -8.6536e-01],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [ 0.0000e+00, -2.1522e+02],\n",
       "        [ 0.0000e+00, -3.4003e+02],\n",
       "        [ 0.0000e+00, -2.0656e+02],\n",
       "        [-7.1526e-07, -1.4197e+01],\n",
       "        [ 0.0000e+00, -4.3608e+02],\n",
       "        [-5.6962e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -2.8464e+02],\n",
       "        [ 0.0000e+00, -1.6834e+02],\n",
       "        [-7.9937e+00, -3.3760e-04],\n",
       "        [-7.4389e+01,  0.0000e+00],\n",
       "        [-7.8300e-02, -2.5861e+00],\n",
       "        [ 0.0000e+00, -7.7199e+01],\n",
       "        [ 0.0000e+00, -6.3662e+01],\n",
       "        [-4.1558e+02,  0.0000e+00],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [-1.0515e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -5.3033e+02],\n",
       "        [-1.9115e+01,  0.0000e+00],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [ 0.0000e+00, -1.9016e+02],\n",
       "        [ 0.0000e+00, -1.8979e+02],\n",
       "        [-2.1677e+01,  0.0000e+00],\n",
       "        [ 0.0000e+00, -1.5885e+02],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [ 0.0000e+00, -8.9975e+01],\n",
       "        [ 0.0000e+00, -1.7256e+02],\n",
       "        [-7.6581e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -6.6236e+01],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [-5.2317e+00, -5.3558e-03],\n",
       "        [-3.2384e+02,  0.0000e+00],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [ 0.0000e+00, -2.6554e+02],\n",
       "        [ 0.0000e+00, -1.5078e+02],\n",
       "        [-5.2553e+02,  0.0000e+00],\n",
       "        [-7.1235e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -1.0629e+02],\n",
       "        [ 0.0000e+00, -1.1910e+02],\n",
       "        [-6.0450e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -4.9588e+01],\n",
       "        [-8.1260e+00, -2.9755e-04],\n",
       "        [ 0.0000e+00, -1.3670e+02],\n",
       "        [ 0.0000e+00, -5.3493e+01],\n",
       "        [ 0.0000e+00, -2.9044e+02],\n",
       "        [-2.5588e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -2.6388e+01],\n",
       "        [ 0.0000e+00, -3.0710e+02],\n",
       "        [ 0.0000e+00, -4.4765e+01],\n",
       "        [ 0.0000e+00, -1.2489e+02],\n",
       "        [ 0.0000e+00, -1.8086e+02],\n",
       "        [-4.2558e+01,  0.0000e+00],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [ 0.0000e+00, -6.7542e+01],\n",
       "        [-8.6737e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -6.8822e+01],\n",
       "        [-1.0779e+03,  0.0000e+00],\n",
       "        [ 0.0000e+00, -3.4903e+02],\n",
       "        [ 0.0000e+00, -7.5785e+02],\n",
       "        [-5.1189e+02,  0.0000e+00],\n",
       "        [-2.1312e+01,  0.0000e+00],\n",
       "        [-8.5901e+01,  0.0000e+00],\n",
       "        [ 0.0000e+00, -6.0842e+01],\n",
       "        [-3.0994e+02,  0.0000e+00],\n",
       "        [-3.1169e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -9.4705e+01],\n",
       "        [ 0.0000e+00, -6.5142e+01],\n",
       "        [-6.7726e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -4.3273e+02],\n",
       "        [ 0.0000e+00, -6.2363e+01],\n",
       "        [-9.2987e-02, -2.4215e+00],\n",
       "        [-1.1677e+02,  0.0000e+00],\n",
       "        [-4.6091e-01, -9.9615e-01],\n",
       "        [ 0.0000e+00, -3.2300e+02],\n",
       "        [ 0.0000e+00, -8.6031e+01],\n",
       "        [ 0.0000e+00, -2.4144e+02],\n",
       "        [-1.0757e+01, -2.0981e-05],\n",
       "        [ 0.0000e+00, -3.0380e+02],\n",
       "        [ 0.0000e+00, -2.5480e+02],\n",
       "        [-2.3695e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -1.1695e+02],\n",
       "        [-3.2988e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -3.3889e+02],\n",
       "        [ 0.0000e+00, -1.8958e+02],\n",
       "        [ 0.0000e+00, -3.1666e+02],\n",
       "        [ 0.0000e+00, -2.1513e+02],\n",
       "        [-4.6347e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -7.2994e+01],\n",
       "        [ 0.0000e+00, -3.2691e+01],\n",
       "        [ 0.0000e+00, -3.3034e+02],\n",
       "        [-6.7035e+01,  0.0000e+00],\n",
       "        [-6.3627e+01,  0.0000e+00],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [ 0.0000e+00, -1.3233e+02],\n",
       "        [ 0.0000e+00, -5.5870e+02],\n",
       "        [-4.3051e+02,  0.0000e+00],\n",
       "        [-2.6940e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -1.4637e+02],\n",
       "        [ 0.0000e+00, -1.5563e+02],\n",
       "        [-4.5916e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -2.2805e+02],\n",
       "        [ 0.0000e+00, -3.9721e+01],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [ 0.0000e+00, -3.6279e+02],\n",
       "        [ 0.0000e+00, -7.0793e+01],\n",
       "        [ 0.0000e+00, -2.6569e+01],\n",
       "        [ 0.0000e+00, -4.2192e+01],\n",
       "        [ 0.0000e+00, -2.3111e+02],\n",
       "        [ 0.0000e+00, -7.0890e+01],\n",
       "        [ 0.0000e+00, -6.9194e+01],\n",
       "        [ 0.0000e+00, -1.2822e+02],\n",
       "        [ 0.0000e+00, -5.1263e+01],\n",
       "        [ 0.0000e+00, -8.6844e+01],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [ 0.0000e+00, -8.5383e+01],\n",
       "        [ 0.0000e+00, -4.0475e+01],\n",
       "        [-1.4037e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -1.5784e+01],\n",
       "        [ 0.0000e+00, -1.3159e+02],\n",
       "        [-3.1849e+02,  0.0000e+00],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [ 0.0000e+00, -1.1552e+03],\n",
       "        [-5.2311e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -3.1154e+02],\n",
       "        [-4.2951e+02,  0.0000e+00],\n",
       "        [-2.1812e+02,  0.0000e+00],\n",
       "        [-5.7286e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -5.1885e+02],\n",
       "        [ 0.0000e+00, -1.6217e+02],\n",
       "        [ 0.0000e+00, -1.1876e+02],\n",
       "        [-1.7450e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -4.0332e+01],\n",
       "        [ 0.0000e+00, -1.5367e+02],\n",
       "        [-7.7145e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -1.6375e+02],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [-1.1959e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -2.3807e+02],\n",
       "        [ 0.0000e+00, -3.6997e+02],\n",
       "        [ 0.0000e+00, -1.1564e+02],\n",
       "        [-7.0022e+02,  0.0000e+00],\n",
       "        [-1.1575e+01, -7.6294e-06],\n",
       "        [-1.8555e-02, -3.9967e+00],\n",
       "        [ 0.0000e+00, -8.0328e+01],\n",
       "        [-4.9592e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -4.5563e+02],\n",
       "        [-1.2352e+03,  0.0000e+00],\n",
       "        [ 0.0000e+00, -3.9428e+01],\n",
       "        [ 0.0000e+00, -1.3536e+02],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [ 0.0000e+00, -2.8850e+01],\n",
       "        [ 0.0000e+00, -1.3796e+02],\n",
       "        [ 0.0000e+00, -2.3622e+02],\n",
       "        [-1.8778e+02,  0.0000e+00],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [ 0.0000e+00, -5.6769e+02],\n",
       "        [-6.4794e+00, -1.5364e-03],\n",
       "        [-7.7097e+01,  0.0000e+00],\n",
       "        [ 0.0000e+00, -2.4131e+02],\n",
       "        [ 0.0000e+00, -8.4919e+01],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [ 0.0000e+00, -3.8032e+01],\n",
       "        [-7.6940e+02,  0.0000e+00],\n",
       "        [-3.7956e+02,  0.0000e+00],\n",
       "        [-1.3599e+03,  0.0000e+00],\n",
       "        [-8.6935e-01, -5.4339e-01],\n",
       "        [ 0.0000e+00, -2.8327e+02],\n",
       "        [ 0.0000e+00, -3.9746e+02],\n",
       "        [-2.8125e+02,  0.0000e+00],\n",
       "        [-6.5117e+02,  0.0000e+00],\n",
       "        [-1.2899e+02,  0.0000e+00],\n",
       "        [-9.4007e+01,  0.0000e+00],\n",
       "        [-2.7522e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -2.0139e+02],\n",
       "        [ 0.0000e+00, -7.6282e+01],\n",
       "        [ 0.0000e+00, -1.8199e+02],\n",
       "        [-8.9772e+02,  0.0000e+00],\n",
       "        [-8.7977e+00, -1.5068e-04],\n",
       "        [-7.7197e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -2.0616e+02],\n",
       "        [ 0.0000e+00, -8.0900e+01],\n",
       "        [ 0.0000e+00, -1.6676e+02],\n",
       "        [-7.5391e+01,  0.0000e+00],\n",
       "        [ 0.0000e+00, -1.5156e+01],\n",
       "        [ 0.0000e+00, -8.2147e+01],\n",
       "        [ 0.0000e+00, -1.9532e+02],\n",
       "        [-1.1044e+02,  0.0000e+00],\n",
       "        [-1.1867e-01, -2.1901e+00],\n",
       "        [-4.4448e+02,  0.0000e+00],\n",
       "        [-2.2153e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -1.5629e+02],\n",
       "        [ 0.0000e+00, -2.0976e+02],\n",
       "        [-6.1553e+01,  0.0000e+00],\n",
       "        [ 0.0000e+00, -3.6596e+02],\n",
       "        [-7.0507e-01, -6.8136e-01],\n",
       "        [-2.3842e-06, -1.2935e+01],\n",
       "        [ 0.0000e+00, -4.6227e+01],\n",
       "        [-4.4944e+02,  0.0000e+00],\n",
       "        [-1.7703e+02,  0.0000e+00],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [-4.1444e-01, -1.0809e+00],\n",
       "        [-9.7914e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -1.4613e+02],\n",
       "        [ 0.0000e+00, -8.7563e+01],\n",
       "        [ 0.0000e+00, -2.6562e+02],\n",
       "        [ 0.0000e+00, -1.5977e+02],\n",
       "        [-5.0355e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -6.4179e+02],\n",
       "        [ 0.0000e+00, -1.7135e+02],\n",
       "        [ 0.0000e+00, -1.6774e+01],\n",
       "        [-8.7921e+00, -1.5259e-04],\n",
       "        [-2.1666e+01,  0.0000e+00],\n",
       "        [-6.3049e+02,  0.0000e+00],\n",
       "        [-3.3379e-05, -1.0302e+01],\n",
       "        [-7.7127e+00, -4.4632e-04],\n",
       "        [-4.8235e-01, -9.6058e-01],\n",
       "        [-1.4781e+01,  0.0000e+00],\n",
       "        [ 0.0000e+00, -3.2199e+02],\n",
       "        [-1.3025e+00, -3.1723e-01],\n",
       "        [ 0.0000e+00, -2.2410e+02],\n",
       "        [-3.5409e+02,  0.0000e+00],\n",
       "        [-1.6967e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -4.7661e+01],\n",
       "        [ 0.0000e+00, -6.5921e+01],\n",
       "        [-1.1681e+00, -3.7244e-01],\n",
       "        [ 0.0000e+00, -1.8642e+02],\n",
       "        [ 0.0000e+00, -9.5224e+01],\n",
       "        [ 0.0000e+00, -3.8487e+01],\n",
       "        [ 0.0000e+00, -1.6209e+02],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [ 0.0000e+00, -6.6655e+01],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [-5.6352e+02,  0.0000e+00],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [ 0.0000e+00, -6.3479e+01],\n",
       "        [ 0.0000e+00, -5.2176e+01],\n",
       "        [ 0.0000e+00, -5.8523e+01],\n",
       "        [ 0.0000e+00, -1.2366e+02],\n",
       "        [-9.6132e+01,  0.0000e+00],\n",
       "        [ 0.0000e+00, -1.2688e+02],\n",
       "        [-3.8708e-01, -1.1364e+00],\n",
       "        [-1.1180e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -6.8145e+01],\n",
       "        [-5.8055e-05, -9.7546e+00],\n",
       "        [-1.3420e+00, -3.0290e-01],\n",
       "        [ 0.0000e+00, -6.3528e+02],\n",
       "        [-4.1070e+02,  0.0000e+00],\n",
       "        [-2.0532e+02,  0.0000e+00],\n",
       "        [-1.5373e-03, -6.4781e+00],\n",
       "        [ 0.0000e+00, -2.4178e+02],\n",
       "        [-6.6808e+02,  0.0000e+00],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [-2.3746e-04, -8.3474e+00],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [ 0.0000e+00, -5.2577e+02],\n",
       "        [ 0.0000e+00, -9.9169e+01],\n",
       "        [ 0.0000e+00, -1.9343e+02],\n",
       "        [-7.5243e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -1.3606e+02],\n",
       "        [ 0.0000e+00, -4.6328e+01],\n",
       "        [ 0.0000e+00, -6.4512e+01],\n",
       "        [ 0.0000e+00, -1.4141e+02],\n",
       "        [-1.1061e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -5.8638e+01],\n",
       "        [-3.7292e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -1.4845e+02],\n",
       "        [ 0.0000e+00, -3.9633e+02],\n",
       "        [-3.5739e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -4.8956e+02],\n",
       "        [ 0.0000e+00, -3.3841e+02],\n",
       "        [-1.1298e+00, -3.9025e-01],\n",
       "        [-4.6323e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -2.1178e+02],\n",
       "        [ 0.0000e+00, -1.4937e+02],\n",
       "        [ 0.0000e+00, -2.1201e+02],\n",
       "        [ 0.0000e+00, -5.9392e+01],\n",
       "        [ 0.0000e+00, -2.2119e+02],\n",
       "        [ 0.0000e+00, -7.2999e+01],\n",
       "        [ 0.0000e+00, -1.5079e+02],\n",
       "        [-4.8445e+01,  0.0000e+00],\n",
       "        [ 0.0000e+00, -4.4211e+01],\n",
       "        [ 0.0000e+00, -2.3571e+02],\n",
       "        [-2.6317e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -1.4675e+02],\n",
       "        [ 0.0000e+00, -1.6064e+02],\n",
       "        [ 0.0000e+00, -1.9367e+02],\n",
       "        [-1.3425e+02,  0.0000e+00],\n",
       "        [-5.8104e+01,  0.0000e+00],\n",
       "        [ 0.0000e+00, -8.5222e+01],\n",
       "        [ 0.0000e+00, -6.3133e+01],\n",
       "        [ 0.0000e+00, -1.0846e+02],\n",
       "        [ 0.0000e+00, -3.3628e+01],\n",
       "        [-1.4531e-01, -2.0007e+00],\n",
       "        [ 0.0000e+00, -3.6580e+01],\n",
       "        [ 0.0000e+00, -3.7137e+01],\n",
       "        [ 0.0000e+00, -2.6811e+02],\n",
       "        [-1.3455e+02,  0.0000e+00],\n",
       "        [-1.3378e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -1.1213e+02],\n",
       "        [-1.9402e+03,  0.0000e+00],\n",
       "        [-4.5135e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -2.9769e+02],\n",
       "        [ 0.0000e+00, -1.0586e+02],\n",
       "        [-1.0430e+02,  0.0000e+00],\n",
       "        [-1.0582e+03,  0.0000e+00],\n",
       "        [ 0.0000e+00, -3.1569e+02],\n",
       "        [ 0.0000e+00, -2.1765e+02],\n",
       "        [ 0.0000e+00, -3.4938e+01],\n",
       "        [-2.3063e+02,  0.0000e+00],\n",
       "        [ 0.0000e+00, -4.0809e+01],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [-1.4966e+00, -2.5346e-01],\n",
       "        [ 0.0000e+00, -6.1793e+01],\n",
       "        [ 0.0000e+00, -5.2910e+01],\n",
       "        [ 0.0000e+00, -2.6227e+02],\n",
       "        [-5.8684e-01, -8.1211e-01],\n",
       "        [-7.0586e+01,  0.0000e+00],\n",
       "        [-6.0501e-02, -2.8351e+00],\n",
       "        [ 0.0000e+00, -9.0491e+01],\n",
       "        [-1.0288e+03,  0.0000e+00],\n",
       "        [ 0.0000e+00, -1.3498e+02],\n",
       "        [-1.2888e+01, -1.9073e-06]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify that the weights are there\n",
    "bnet2 = BayesNet(num_ftrs)\n",
    "bnet2.load_state_dict(ckptb['model10'])\n",
    "F.log_softmax(bnet2(torch.tensor(test_features)), 1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ddsm_experiment_cropped_cv.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
